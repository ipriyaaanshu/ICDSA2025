{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gleaning: Iterative Self-Critique for LLMs\n",
    "\n",
    "This notebook demonstrates the *gleaning* patternâ€”an iterative draft, critique, and revise loop for improving LLM outputs at inference time. Inspired by Anthropic's Constitutional AI and recent research, this approach can boost quality and safety without extra model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Gleaning?\n",
    "\n",
    "Gleaning is an inference-time self-review loop for LLMs:\n",
    "1. **Draft**: Generate an initial output.\n",
    "2. **Critique**: The model reviews its own output and suggests improvements.\n",
    "3. **Revise**: The model revises its output based on the critique.\n",
    "4. **Repeat**: Loop until a quality gate is passed or a maximum number of iterations is reached.\n",
    "\n",
    "This mimics human editing and can be implemented with any LLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirascope import llm, prompt_template\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Critique(BaseModel):\n",
    " feedback: str\n",
    " needs_improvement: bool\n",
    "\n",
    "@llm.call(provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "@prompt_template(\"Write a polite email declining a job offer for: {role}\")\n",
    "def draft(role: str) -> str: ...\n",
    "\n",
    "@llm.call(provider=\"openai\", model=\"gpt-4o-mini\", response_model=Critique)\n",
    "@prompt_template(\"\"\"\n",
    "                    Evaluate the email and suggest improvements.\n",
    "                    Role: {role}\n",
    "                    Email: {email}\n",
    "                \"\"\")\n",
    "def critique(role: str, email: str) -> Critique: ...\n",
    "\n",
    "@llm.call(provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "@prompt_template(\"\"\"\n",
    "                    Revise the email using this feedback.\n",
    "                    Role: {role}\n",
    "                    Email: {email}\n",
    "                    Feedback: {feedback}\n",
    "                \"\"\")\n",
    "def revise(role: str, email: str, feedback: str) -> str: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Glean Loop\n",
    "\n",
    "This function runs the draft-critique-revise loop up to a maximum number of iterations, or until the critique says no further improvement is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glean(role: str, max_iter: int = 3) -> str:\n",
    "    email = draft(role)\n",
    "    for _ in range(max_iter):\n",
    "        fb = critique(role, email)\n",
    "        print(\"Feedback: \", fb.feedback, end=\"\\n\\n--------------------------------\\n\\n\")\n",
    "        if not fb.needs_improvement:\n",
    "            print(\"No improvement needed\")\n",
    "            return email\n",
    "        email = revise(role, email, fb.feedback)\n",
    "    return email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Polite Email Declining a Job Offer\n",
    "\n",
    "Let's see the gleaning loop in action for the role of 'Data Scientist'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback:  The email is polite and expresses gratitude, which is great. However, it could be improved by being more concise and specific. For example, mentioning what specifically led to the decision to decline (without going into too much detail) might provide clarity. Additionally, a positive remark about the team or a specific project discussed during the interviews could strengthen the connection. Finally, ending with an invitation to keep in touch or a wish that their search for the right candidate is successful could leave a better impression.\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "Feedback:  The email is polite and expresses gratitude; however, it could be improved by mentioning specific reasons for declining the offer to provide closure. Including a stronger expression of interest in potential future opportunities could also enhance the connection. Furthermore, consider personalizing the email with specific details about the interactions or insights from the interview that were particularly meaningful. This would make the message more memorable and display genuine appreciation.\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "Feedback:  The email is polite and expresses gratitude for the job offer, which is commendable. However, there are a few areas for improvement. Firstly, it would be beneficial to provide a more specific reason for declining the offer, as this could help the hiring manager understand your decision better. While mentioning your desire to pursue an opportunity aligning with your career aspirations is good, elaborating on what that aspiration is could add clarity. Additionally, consider expressing a strong interest in future collaboration with a specific example of how you see that working, which could make the email more memorable. Finally, ensuring the email is more concise while retaining its warmth would enhance its effectiveness.\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "Subject: Thank You for the Opportunity\n",
      "\n",
      "Dear [Hiring Manager's Name],\n",
      "\n",
      "I hope this message finds you well. I want to extend my heartfelt thanks for offering me the Data Scientist position at [Company Name]. It was a pleasure meeting you and the team, and our discussions about [specific project or topic discussed] were particularly inspiring.\n",
      "\n",
      "After careful consideration, I have decided to decline the offer. This was not an easy decision, as I hold [Company Name] in high regard. Ultimately, I have decided to pursue an opportunity that focuses on [specific area or field], which aligns more closely with my long-term career goals in [more specific aspect of the desired field].\n",
      "\n",
      "I genuinely admire the collaborative culture and the exciting projects at [Company Name], and I would love to explore potential future collaborations. For instance, I would be very interested in contributing to [specific initiative or project discussed] should the opportunity arise later on.\n",
      "\n",
      "Thank you once again for your time and the insights shared during our conversations. I hope to stay connected and wish you all the best in your search for the ideal candidate.\n",
      "\n",
      "Warmest regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your LinkedIn Profile (if applicable)]  \n",
      "[Your Contact Information]  \n"
     ]
    }
   ],
   "source": [
    "final_result = glean('Data Scientist')\n",
    "print(final_result.response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- In a real-world setting, the `draft`, `critique`, and `revise` functions would call an LLM API (e.g., OpenAI, Anthropic) with appropriate prompts.\n",
    "- The critique step can use a structured schema (e.g., Pydantic) to ensure reliable feedback.\n",
    "- This pattern is used in Anthropic's Constitutional AI, which showed large improvements in safety and quality ([Bai et al., 2022](https://arxiv.org/abs/2212.08073)).\n",
    "- You can adapt this notebook to your own tasks by changing the prompts and feedback logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- Bai, Yuntao, et al. \"Constitutional AI: Harmlessness from AI Feedback.\" arXiv preprint arXiv:2212.08073 (2022). [arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)\n",
    "- Madaan, Aman, et al. \"Self-Refine: Iterative Refinement with Self-Feedback.\" arXiv preprint arXiv:2303.17651 (2023). [arxiv.org/abs/2303.17651](https://arxiv.org/abs/2303.17651)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
